% BEGIN TEMPLATE
\documentclass{article}
\usepackage{graphicx}
\usepackage{hyperref} 
\usepackage{xcolor}
\usepackage{nameref}
\usepackage{listings}
\usepackage{float}
\usepackage[title]{appendix}
\usepackage[ruled]{algorithm2e}
\graphicspath{ {../../images/} }
\bibliographystyle{acm}
% CHANGE THESE
\newcommand{\courseListing}{CSCI 8150}
\newcommand{\courseName}{Advanced Computer Architecture}
\newcommand{\assignmentTitle}{Final Exam}
\newcommand{\assignmentSubtitle}{Paper Summary and Problem Solutions}
\usepackage{geometry}
\geometry{margin=1in}
\renewcommand{\baselinestretch}{1.5}


\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\urlstyle{same}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}
  \input{../../templates/titlepage.tex}
  \graphicspath{{./images/}}
% END TEMPLATE

\section{Introduction and Uniprocessor Baseline}

\par At the highest level, the paper \textit{Shared Memory Consistency Models: A Tutorial} covers the problem of memory consistency in multiprocessor systems.
Put simply, the general problem is similar to problems covered in class, where one processor might access a specific field of shared data, observing old or incorrect (strictly in terms of the programmatic flow) data prior to completion of some unrelated operation from a different processor.
This is a critical issue to address from a systems perspective, because programmers may not be able to solve the problem on their own without introducing timing uncertainty to processes.
Moreover, allowing programs to assume that the memory they get is correct aids in making programs universal, which is to say that a program \textit{should} be able to run the same way on any system, regardless of the specific architecture of its processors and memory.

\par To establish a comparison point for the consistency models in multiprocessor systems, the authors first discuss memory semantics in uniprocessor systems.
This is intuitive--when memory operations occur in a uniprocessor system, they occur in program order, so that any instructions executed in the same location happen sequentially.
It also allows for many of the conventions associated with processor systems--pipelining, loops, and lockup-free caches, to name some.

\section{Sequential Consistency}

\par Having established a baseline behavior and programmer expectation for how memory operations behave, the authors go on to outline models for replicating these expectations in multiprocessor systems.
The first such model is \textit{sequential consistency}, which is fundamentally a method to ensure that program order is maintained by a memory system for individual processors while also establishing a single order for all instructions being processed, across all processors.
This provides the appearance of atomic execution, allowing different processes to execute reliably and have their changes reflected across the entire system, simultaneously. The authors go on to describe implementation optimizations, and their associated problems for sequential consistency, in a few common hardware configurations. 

\par The first configuration covered is \textbf{Architectures Without Caches}.
One problem in such architectures can be found in write buffers; sequential consistency can be compromised if, for example, each of two processors can buffer its own write, allowing some subsequent read to bypass it in the buffer and read incorrect data that \textit{should} be properly modified by the other processor.

\par Another problem is with allowing write operations to overlap.
In the example the authors provide, a bus (but not a cache) connects multiple processors to multiple memory modules, and may "deliver" data from two writes to different modules out of program order.
Then, another process executes incorrectly because it reads the data in "delivery order" instead of "sequential order."
The data is no longer sequentially consistent.

\par The third possible issue with cache-less architectures can be found in non-blocking read operations.
This is similar to overlapping write operations, but arises when one processor's read operations are executed in an overlapping fashion, possibly causing that processor to read a memory location before data from another processor's write command has reached it.

\par Having established possible sequential consistency violations in hardware optimizations for architectures without caches, the authors move on to discuss \textbf{Architectures with Caches}.
Caching provides general protections for frequently-accessed memory locations, but its associated optimizations each present the possibility of sequential consistency violations.
One such optimization is cache coherence.
The authors argue that the concept of cache coherence--that each write be made visible to all processors, such that each write appears in sequential order--is insufficient to guarantee sequential consistency.
As a mechanism to protect memory, they argue that cache coherence is valuable, but the concept in and of itself 


\end{document}